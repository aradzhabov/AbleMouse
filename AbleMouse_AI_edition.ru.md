# AbleMouse AI edition

> ❤️ Управление курсором мыши с помощью лица. В точку по направлению, куда указывает нос, позиционируется курсор, а клики делаются глазами и ртом. Позиционирование происходит именно по направлению, т.е. экран может быть любого размера, но человеку никуда не нужно двигаться - нужно просто направить нос в точку, куда переместить курсор.
> 
> Код работает в Windows и macOS. Примечание: поддержка Unix/Ubuntu возможна, но требует тестирования.

>▶️ [Видео AbleMouse AI edition](https://rutube.ru/video/c27362a9037dbe7b9ceb7fb06f275b4c/)
> / [Исходный код](src/ablemouse_ai_edition/able_mouse_ai_edition.py) / ▶️ [Первоначальная настройка](https://youtu.be/KCn4GMMQkxc)
> 
> Примечание: В видеодемонстрации для вызова экранной клавиатуры в Windows я использовал распознавание жестов через [MouseCommander (win)](https://github.com/aradzhabov/AbleMouse/blob/main/src/windows/auto_hot_key/README.md), который также является частью проекта AbleMouse. <br> На macOS нет необходимости использовать MouseCommander, так как встроенная клавиатура с включенной функцией «ожидания» (dwelling) и настраиваемой прозрачностью очень удобна и не загромождает интерфейс.

<img src="docs/img/ablemouse_ai_icon.jpg" alt="AbleMouse AI edition" style="width: 250px; border: 2px solid #ccc; border-radius: 10px;" />

Важным аспектом является то, что это решение полностью открыто (open-source) и может быть легко адаптировано под нужды конкретного человека.

Для использования AbleMouse AI edition достаточно иметь возможность поворачивать и наклонять голову, а также задействовать глаза и рот. 
Курсор мыши позиционируется в зависимости от направления вашего носа, что позволяет эффективно работать даже с очень большими экранами. 
В macOS и Windows подобных встроенных решений нет. 

Еще одно очень важное отличие от других систем заключается в том, что ваши глаза остаются свободными, так как трекинг основан на направлении носа. Это обеспечивает гораздо более естественное ощущение для человека. Например, решения, требующие смотреть именно в ту точку, куда вы хотите переместить курсор, требуют значительно больше усилий и кажутся неестественными. Обычный человек, использующий ручную мышь, может смотреть куда угодно — AbleMouse позволяет делать то же самое.

### Несколько заметок по использованию и настройке:

*   Для адаптации программы под конкретного человека потребуется помощь кого-то с базовыми знаниями Python. На мой взгляд, уровня школьника будет достаточно. 
    Само решение очень простое и по сути состоит из одного файла, где нужно подправить настройки под конкретного пользователя. Большинство параметров в коде интуитивно понятны по их названиям, и во многих случаях их даже не придется менять. Ниже я опишу самые важные из них. Пожалуйста, не стесняйтесь писать мне, если у вас возникнут вопросы.

*   Я рекомендую использовать внешнюю веб-камеру, так как это обеспечивает максимальный комфорт в расположении экрана, особенно для лежачих больных. 
    Если вы используете внешнюю камеру, вам нужно установить параметр `camera` в значение, отличное от 0 (обычно это 1). Значение 0 соответствует встроенной камере ноутбука.

*   `EYE_CLOSE_THRESHOLD` — пороги для определения закрытых глаз (расстояние между верхними и нижними ресницами).
    `MOUTH_OPEN_THRESHOLD` — порог для определения открытого рта (расстояние между губами).

Важно понимать, что эти параметры сильно зависят от расстояния лица до камеры и самой модели камеры. Также нужно учитывать, что, например, при наклоне головы расстояние между расчетными точками уменьшается из-за проекции. При запуске программы вы сможете легко проверить работу со своими настройками: откроется окно, отображающее каждый жест. Это же окно можно использовать для тренировки. Окно будет оставаться открытым во время работы программы, но его можно скрыть за другими приложениями — на работу это не влияет.

*   Для Python-разработчиков: `Python 3.9-3.12`. Для запуска программы нужно создать виртуальное окружение (venv) и установить всего 3 пакета: 
    `opencv-python`, `mediapipe==0.10.21`, `pyautogui`. 
    После этого запустите [able_mouse_ai_edition.py](src/ablemouse_ai_edition/able_mouse_ai_edition.py). !!После запуска не забудьте правильно [откалибровать положение камеры](https://youtu.be/KCn4GMMQkxc)!!

*   В целом, я рассматриваю эту программу и как образовательный момент. Думаю, многие студенты смогут почерпнуть здесь что-то полезное для себя. 
    Сама программа — это максимально упрощенный, небольшой «срез» из моей R&D версии двухлетней давности. 

    Я мог бы значительно упростить код, используя инструкции `sleep` вместо кулдаунов (cooldowns), но мой опыт показывает, что такие замирания очень заметны и ощущаются неестественно. Также я намеренно не публиковал чистую объектно-ориентированную версию кода, так как новичкам будет гораздо проще разобраться в версии без ООП.

## Поддержка
- aradzhabov@gmail.com
- [LinkedIn](https://www.linkedin.com/in/aradzhabov/)

## Лицензия

MIT License — подробности в файле [LICENSE](LICENSE).

---

### Свяжитесь с нами

[![Website](https://img.shields.io/badge/Website-Learn%20More-green)](https://aradzhabov.github.io/gagarin_data_labs/)

**#Accessibility #AssistiveTech #OpenSource #DIY #Innovation #MouthPad #eye-tracker #NeuralNetworks**
